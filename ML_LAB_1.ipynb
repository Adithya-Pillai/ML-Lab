{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = 'housing.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(\"\\nDataset Information:\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nStatistical Information of Numerical Columns:\")\n",
        "print(df.describe())\n",
        "\n",
        "print(\"\\nUnique Labels Count for 'Ocean Proximity' column:\")\n",
        "print(df['ocean_proximity'].value_counts())\n",
        "\n",
        "print(\"\\nAttributes with Missing Values:\")\n",
        "missing_values = df.isnull().sum()\n",
        "columns_with_missing_values = missing_values[missing_values > 0]\n",
        "print(columns_with_missing_values)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOI8E7OXblp-",
        "outputId": "85071cca-9ed7-4c4c-873b-1570e8dc92c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20640 entries, 0 to 20639\n",
            "Data columns (total 10 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   longitude           20640 non-null  float64\n",
            " 1   latitude            20640 non-null  float64\n",
            " 2   housing_median_age  20640 non-null  float64\n",
            " 3   total_rooms         20640 non-null  float64\n",
            " 4   total_bedrooms      20433 non-null  float64\n",
            " 5   population          20640 non-null  float64\n",
            " 6   households          20640 non-null  float64\n",
            " 7   median_income       20640 non-null  float64\n",
            " 8   median_house_value  20640 non-null  float64\n",
            " 9   ocean_proximity     20640 non-null  object \n",
            "dtypes: float64(9), object(1)\n",
            "memory usage: 1.6+ MB\n",
            "None\n",
            "\n",
            "Statistical Information of Numerical Columns:\n",
            "          longitude      latitude  housing_median_age   total_rooms  \\\n",
            "count  20640.000000  20640.000000        20640.000000  20640.000000   \n",
            "mean    -119.569704     35.631861           28.639486   2635.763081   \n",
            "std        2.003532      2.135952           12.585558   2181.615252   \n",
            "min     -124.350000     32.540000            1.000000      2.000000   \n",
            "25%     -121.800000     33.930000           18.000000   1447.750000   \n",
            "50%     -118.490000     34.260000           29.000000   2127.000000   \n",
            "75%     -118.010000     37.710000           37.000000   3148.000000   \n",
            "max     -114.310000     41.950000           52.000000  39320.000000   \n",
            "\n",
            "       total_bedrooms    population    households  median_income  \\\n",
            "count    20433.000000  20640.000000  20640.000000   20640.000000   \n",
            "mean       537.870553   1425.476744    499.539680       3.870671   \n",
            "std        421.385070   1132.462122    382.329753       1.899822   \n",
            "min          1.000000      3.000000      1.000000       0.499900   \n",
            "25%        296.000000    787.000000    280.000000       2.563400   \n",
            "50%        435.000000   1166.000000    409.000000       3.534800   \n",
            "75%        647.000000   1725.000000    605.000000       4.743250   \n",
            "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
            "\n",
            "       median_house_value  \n",
            "count        20640.000000  \n",
            "mean        206855.816909  \n",
            "std         115395.615874  \n",
            "min          14999.000000  \n",
            "25%         119600.000000  \n",
            "50%         179700.000000  \n",
            "75%         264725.000000  \n",
            "max         500001.000000  \n",
            "\n",
            "Unique Labels Count for 'Ocean Proximity' column:\n",
            "ocean_proximity\n",
            "<1H OCEAN     9136\n",
            "INLAND        6551\n",
            "NEAR OCEAN    2658\n",
            "NEAR BAY      2290\n",
            "ISLAND           5\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Attributes with Missing Values:\n",
            "total_bedrooms    207\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"diabetes.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 1. Identify missing values\n",
        "missing_values = df.isnull().sum()\n",
        "missing_columns = missing_values[missing_values > 0].index.tolist()\n",
        "print(f\"Columns with missing values: {missing_columns}\")\n",
        "\n",
        "# Handle missing values (Mean imputation for numeric columns)\n",
        "df_numeric = df.select_dtypes(include=['number']).copy()\n",
        "imputer = SimpleImputer(strategy=\"mean\")\n",
        "df_numeric.iloc[:, :] = imputer.fit_transform(df_numeric)\n",
        "df[df_numeric.columns] = df_numeric\n",
        "\n",
        "# 2. Identify categorical columns\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "print(f\"Categorical columns: {categorical_cols}\")\n",
        "\n",
        "# Encode categorical columns using Label Encoding\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le  # Store encoders for inverse transform if needed\n",
        "\n",
        "# 3. Remove outliers using IQR method\n",
        "Q1 = df_numeric.quantile(0.25)\n",
        "Q3 = df_numeric.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "df = df[~((df_numeric < (Q1 - 1.5 * IQR)) | (df_numeric > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "\n",
        "# 4. Apply Min-Max Scaling and Standardization\n",
        "min_max_scaler = MinMaxScaler()\n",
        "df_minmax = pd.DataFrame(min_max_scaler.fit_transform(df_numeric), columns=df_numeric.columns)\n",
        "\n",
        "standard_scaler = StandardScaler()\n",
        "df_standard = pd.DataFrame(standard_scaler.fit_transform(df_numeric), columns=df_numeric.columns)\n",
        "\n",
        "# Display Results\n",
        "print(\"\\nProcessed Diabetes Dataset (Min-Max Scaled):\")\n",
        "print(df_minmax.head())\n",
        "\n",
        "print(\"\\nProcessed Diabetes Dataset (Standard Scaled):\")\n",
        "print(df_standard.head())\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFsupRLccr3E",
        "outputId": "346eb660-a400-4291-ab8d-c5265f1aa0ef"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns with missing values: []\n",
            "Categorical columns: ['Gender', 'CLASS']\n",
            "\n",
            "Processed Diabetes Dataset (Min-Max Scaled):\n",
            "         ID  No_Pation       AGE      Urea        Cr     HbA1c      Chol  \\\n",
            "0  0.627034   0.000237  0.508475  0.109375  0.050378  0.264901  0.407767   \n",
            "1  0.918648   0.000452  0.101695  0.104167  0.070529  0.264901  0.359223   \n",
            "2  0.524406   0.000634  0.508475  0.109375  0.050378  0.264901  0.407767   \n",
            "3  0.849812   0.001160  0.508475  0.109375  0.050378  0.264901  0.407767   \n",
            "4  0.629537   0.000452  0.220339  0.171875  0.050378  0.264901  0.475728   \n",
            "\n",
            "         TG       HDL       LDL      VLDL       BMI  \n",
            "0  0.044444  0.226804  0.114583  0.011461  0.173913  \n",
            "1  0.081481  0.092784  0.187500  0.014327  0.139130  \n",
            "2  0.044444  0.226804  0.114583  0.011461  0.173913  \n",
            "3  0.044444  0.226804  0.114583  0.011461  0.173913  \n",
            "4  0.051852  0.061856  0.177083  0.008596  0.069565  \n",
            "\n",
            "Processed Diabetes Dataset (Standard Scaled):\n",
            "         ID  No_Pation       AGE      Urea        Cr     HbA1c      Chol  \\\n",
            "0  0.672140  -0.074747 -0.401144 -0.144781 -0.382672 -1.334983 -0.509436   \n",
            "1  1.641852  -0.069940 -3.130017 -0.212954 -0.115804 -1.334983 -0.893730   \n",
            "2  0.330868  -0.065869 -0.401144 -0.144781 -0.382672 -1.334983 -0.509436   \n",
            "3  1.412950  -0.054126 -0.401144 -0.144781 -0.382672 -1.334983 -0.509436   \n",
            "4  0.680463  -0.069939 -2.334096  0.673299 -0.382672 -1.334983  0.028576   \n",
            "\n",
            "         TG       HDL       LDL      VLDL       BMI  \n",
            "0 -1.035084  1.810756 -1.085457 -0.369958 -1.124622  \n",
            "1 -0.678063 -0.158692 -0.457398 -0.342649 -1.326239  \n",
            "2 -1.035084  1.810756 -1.085457 -0.369958 -1.124622  \n",
            "3 -1.035084  1.810756 -1.085457 -0.369958 -1.124622  \n",
            "4 -0.963680 -0.613180 -0.547121 -0.397267 -1.729472  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
        "\n",
        "# Step 2: Load the dataset (Ensure it's in the working directory)\n",
        "file_path = \"adult.csv\"  # Update the file path if needed\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Step 3: Handling Missing Values (Replacing '?' with NaN)\n",
        "df.replace(\"?\", np.nan, inplace=True)\n",
        "\n",
        "# Step 4: Check missing values before imputation\n",
        "missing_values_before = df.isna().sum()\n",
        "print(\"\\nColumns with missing values before imputation:\")\n",
        "print(missing_values_before[missing_values_before > 0])\n",
        "\n",
        "# Step 5: Handling Numerical Missing Values with Mean\n",
        "num_imputer = SimpleImputer(strategy=\"mean\")\n",
        "df[df.select_dtypes(include=['number']).columns] = num_imputer.fit_transform(df.select_dtypes(include=['number']))\n",
        "\n",
        "# Step 6: Handling Categorical Missing Values with Mode\n",
        "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
        "df[df.select_dtypes(include=['object']).columns] = cat_imputer.fit_transform(df.select_dtypes(include=['object']))\n",
        "\n",
        "# Step 7: Verify no missing values remain\n",
        "print(\"\\nMissing values after imputation:\")\n",
        "print(df.isna().sum())\n",
        "\n",
        "# Step 8: Handling Categorical Data (Encoding using Label Encoding)\n",
        "label_encoders = {}\n",
        "for col in df.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le  # Store encoders for inverse transform if needed\n",
        "\n",
        "# Step 9: Identifying Outliers using IQR and Removing Them\n",
        "Q1 = df.quantile(0.25)\n",
        "Q3 = df.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "df = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "\n",
        "# Step 10: Data Normalization and Standardization\n",
        "# Min-Max Normalization\n",
        "min_max_scaler = MinMaxScaler()\n",
        "df_minmax = pd.DataFrame(min_max_scaler.fit_transform(df), columns=df.columns)\n",
        "\n",
        "# Standardization (Z-score normalization)\n",
        "standard_scaler = StandardScaler()\n",
        "df_standard = pd.DataFrame(standard_scaler.fit_transform(df), columns=df.columns)\n",
        "\n",
        "# Step 11: Display Processed Data\n",
        "print(\"\\nProcessed Adult Income Dataset (Min-Max Scaled):\")\n",
        "print(df_minmax.head())\n",
        "\n",
        "print(\"\\nProcessed Adult Income Dataset (Standard Scaled):\")\n",
        "print(df_standard.head())\n",
        "\n",
        "# Step 12: Display categorical columns that were encoded\n",
        "categorical_columns = df.select_dtypes(include=['int']).columns  # Categorical columns after encoding\n",
        "print(\"\\nCategorical columns encoded:\")\n",
        "print(categorical_columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNPQp3Cpcu6t",
        "outputId": "af98684d-81c4-4540-cf62-8d4c72ca271c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Columns with missing values before imputation:\n",
            "workclass         2799\n",
            "occupation        2809\n",
            "native-country     857\n",
            "dtype: int64\n",
            "\n",
            "Missing values after imputation:\n",
            "age                0\n",
            "workclass          0\n",
            "fnlwgt             0\n",
            "education          0\n",
            "educational-num    0\n",
            "marital-status     0\n",
            "occupation         0\n",
            "relationship       0\n",
            "race               0\n",
            "gender             0\n",
            "capital-gain       0\n",
            "capital-loss       0\n",
            "hours-per-week     0\n",
            "native-country     0\n",
            "income             0\n",
            "dtype: int64\n",
            "\n",
            "Processed Adult Income Dataset (Min-Max Scaled):\n",
            "        age  workclass    fnlwgt  education  educational-num  marital-status  \\\n",
            "0  0.344262        0.0  0.188277   0.555556         0.363636        0.333333   \n",
            "1  0.114754        0.0  0.881156   1.000000         0.454545        0.666667   \n",
            "2  0.147541        0.0  0.169156   0.555556         0.363636        0.666667   \n",
            "3  0.672131        0.0  0.708251   0.555556         0.363636        0.333333   \n",
            "4  0.131148        0.0  0.475807   0.333333         0.727273        0.333333   \n",
            "\n",
            "   occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
            "0    0.307692           0.0   0.0     1.0           0.0           0.0   \n",
            "1    0.538462           0.8   0.0     0.0           0.0           0.0   \n",
            "2    0.000000           0.2   0.0     0.0           0.0           0.0   \n",
            "3    0.692308           0.0   0.0     1.0           0.0           0.0   \n",
            "4    0.692308           0.0   0.0     1.0           0.0           0.0   \n",
            "\n",
            "   hours-per-week  native-country  income  \n",
            "0        0.894737             0.0     0.0  \n",
            "1        0.368421             0.0     0.0  \n",
            "2        0.315789             0.0     0.0  \n",
            "3        0.105263             0.0     0.0  \n",
            "4        0.368421             0.0     0.0  \n",
            "\n",
            "Processed Adult Income Dataset (Standard Scaled):\n",
            "        age  workclass    fnlwgt  education  educational-num  marital-status  \\\n",
            "0  0.220179        0.0 -1.022983  -0.151256        -0.654083       -0.398228   \n",
            "1 -0.955630        0.0  2.234629   1.457372        -0.073261        0.828047   \n",
            "2 -0.787657        0.0 -1.112882  -0.151256        -0.654083        0.828047   \n",
            "3  1.899906        0.0  1.421707  -0.151256        -0.654083       -0.398228   \n",
            "4 -0.871644        0.0  0.328856  -0.955571         1.669207       -0.398228   \n",
            "\n",
            "   occupation  relationship  race    gender  capital-gain  capital-loss  \\\n",
            "0   -0.420679     -1.044582   0.0  0.770972           0.0           0.0   \n",
            "1    0.305840      1.629927   0.0 -1.297064           0.0           0.0   \n",
            "2   -1.389371     -0.375955   0.0 -1.297064           0.0           0.0   \n",
            "3    0.790186     -1.044582   0.0  0.770972           0.0           0.0   \n",
            "4    0.790186     -1.044582   0.0  0.770972           0.0           0.0   \n",
            "\n",
            "   hours-per-week  native-country  income  \n",
            "0        2.312838             0.0     0.0  \n",
            "1       -0.329781             0.0     0.0  \n",
            "2       -0.594043             0.0     0.0  \n",
            "3       -1.651090             0.0     0.0  \n",
            "4       -0.329781             0.0     0.0  \n",
            "\n",
            "Categorical columns encoded:\n",
            "Index(['workclass', 'education', 'marital-status', 'occupation',\n",
            "       'relationship', 'race', 'gender', 'native-country', 'income'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    }
  ]
}